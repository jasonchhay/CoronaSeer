{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/data/szr207/datasets/covid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>Microsoft Academic Paper ID</th>\n",
       "      <th>WHO #Covidence</th>\n",
       "      <th>has_full_text</th>\n",
       "      <th>full_text_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Intrauterine virus infections and congenital h...</td>\n",
       "      <td>10.1016/0002-8703(72)90077-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4361535</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract The etiologic basis for the vast majo...</td>\n",
       "      <td>1972-12-31</td>\n",
       "      <td>Overall, James C.</td>\n",
       "      <td>American Heart Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Coronaviruses in Balkan nephritis</td>\n",
       "      <td>10.1016/0002-8703(80)90355-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6243850</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-03-31</td>\n",
       "      <td>Georgescu, Leonida; Diosi, Peter; Buţiu, Ioan;...</td>\n",
       "      <td>American Heart Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Cigarette smoking and coronary heart disease: ...</td>\n",
       "      <td>10.1016/0002-8703(80)90356-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7355701</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-03-31</td>\n",
       "      <td>Friedman, Gary D</td>\n",
       "      <td>American Heart Journal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aecbc613ebdab36753235197ffb4f35734b5ca63</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Clinical and immunologic studies in identical ...</td>\n",
       "      <td>10.1016/0002-9343(73)90176-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4579077</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract Middle-aged female identical twins, o...</td>\n",
       "      <td>1973-08-31</td>\n",
       "      <td>Brunner, Carolyn M.; Horwitz, David A.; Shann,...</td>\n",
       "      <td>The American Journal of Medicine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>Epidemiology of community-acquired respiratory...</td>\n",
       "      <td>10.1016/0002-9343(85)90361-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4014285</td>\n",
       "      <td>els-covid</td>\n",
       "      <td>Abstract Upper respiratory tract infections ar...</td>\n",
       "      <td>1985-06-28</td>\n",
       "      <td>Garibaldi, Richard A.</td>\n",
       "      <td>The American Journal of Medicine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>custom_license</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sha  source_x  \\\n",
       "0                                       NaN  Elsevier   \n",
       "1                                       NaN  Elsevier   \n",
       "2                                       NaN  Elsevier   \n",
       "3  aecbc613ebdab36753235197ffb4f35734b5ca63  Elsevier   \n",
       "4                                       NaN  Elsevier   \n",
       "\n",
       "                                               title  \\\n",
       "0  Intrauterine virus infections and congenital h...   \n",
       "1                  Coronaviruses in Balkan nephritis   \n",
       "2  Cigarette smoking and coronary heart disease: ...   \n",
       "3  Clinical and immunologic studies in identical ...   \n",
       "4  Epidemiology of community-acquired respiratory...   \n",
       "\n",
       "                            doi pmcid pubmed_id    license  \\\n",
       "0  10.1016/0002-8703(72)90077-4   NaN   4361535  els-covid   \n",
       "1  10.1016/0002-8703(80)90355-5   NaN   6243850  els-covid   \n",
       "2  10.1016/0002-8703(80)90356-7   NaN   7355701  els-covid   \n",
       "3  10.1016/0002-9343(73)90176-9   NaN   4579077  els-covid   \n",
       "4  10.1016/0002-9343(85)90361-4   NaN   4014285  els-covid   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  Abstract The etiologic basis for the vast majo...   1972-12-31   \n",
       "1                                                NaN   1980-03-31   \n",
       "2                                                NaN   1980-03-31   \n",
       "3  Abstract Middle-aged female identical twins, o...   1973-08-31   \n",
       "4  Abstract Upper respiratory tract infections ar...   1985-06-28   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                  Overall, James C.   \n",
       "1  Georgescu, Leonida; Diosi, Peter; Buţiu, Ioan;...   \n",
       "2                                   Friedman, Gary D   \n",
       "3  Brunner, Carolyn M.; Horwitz, David A.; Shann,...   \n",
       "4                              Garibaldi, Richard A.   \n",
       "\n",
       "                            journal Microsoft Academic Paper ID  \\\n",
       "0            American Heart Journal                         NaN   \n",
       "1            American Heart Journal                         NaN   \n",
       "2            American Heart Journal                         NaN   \n",
       "3  The American Journal of Medicine                         NaN   \n",
       "4  The American Journal of Medicine                         NaN   \n",
       "\n",
       "  WHO #Covidence  has_full_text  full_text_file  \n",
       "0            NaN          False  custom_license  \n",
       "1            NaN          False  custom_license  \n",
       "2            NaN          False  custom_license  \n",
       "3            NaN           True  custom_license  \n",
       "4            NaN          False  custom_license  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = f'{data_root}/metadata.csv'\n",
    "meta_df = pd.read_csv(metadata_path, dtype={\n",
    "    'pubmed_id': str,\n",
    "    'Microsoft Academic Paper ID': str, \n",
    "    'doi': str\n",
    "})\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11047"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df[\"journal\"].isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29315"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_json = glob.glob(f'{data_root}/**/*.json', recursive=True)\n",
    "len(all_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileReader:\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path) as file:\n",
    "            content = json.load(file)\n",
    "            self.paper_id = content['paper_id']\n",
    "            self.abstract = []\n",
    "            self.body_text = []\n",
    "            self.metadata = {}\n",
    "            if 'metadata' in content:\n",
    "                self.metadata = content['metadata']\n",
    "            # Abstract\n",
    "            for entry in content['abstract']:\n",
    "                self.abstract.append(entry['text'])\n",
    "            # Body text\n",
    "            for entry in content['body_text']:\n",
    "                self.body_text.append(entry['text'])\n",
    "            self.abstract = '\\n'.join(self.abstract)\n",
    "            self.body_text = '\\n'.join(self.body_text)\n",
    "    def __repr__(self):\n",
    "        return f'{self.paper_id}: {self.abstract}... {self.body_text}...{self.metadata}'\n",
    "# first_row = FileReader(all_json[0])\n",
    "# print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_breaks(content, length):\n",
    "    data = \"\"\n",
    "    words = content.split(' ')\n",
    "    total_chars = 0\n",
    "\n",
    "    # add break every length characters\n",
    "    for i in range(len(words)):\n",
    "        total_chars += len(words[i])\n",
    "        if total_chars > length:\n",
    "            data = data + \"<br>\" + words[i]\n",
    "            total_chars = 0\n",
    "        else:\n",
    "            data = data + \" \" + words[i]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76cd65c50ed4227b523bf4ae7c2409b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def check_nan(num):\n",
    "    return num != num\n",
    "\n",
    "list_json = []\n",
    "\n",
    "for idx, entry in tqdm(enumerate(all_json)):\n",
    "    dict_ = {}\n",
    "#     if idx % (len(all_json) // 10) == 0:\n",
    "#         print(f'Processing index: {idx} of {len(all_json)}')\n",
    "    content = FileReader(entry)\n",
    "    \n",
    "    # get metadata information\n",
    "    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n",
    "    # no metadata, skip this paper\n",
    "    if len(meta_data) == 0:\n",
    "        continue\n",
    "#     print(meta_data)\n",
    "    dict_['paper_id'] = content.paper_id\n",
    "    dict_['abstract'] = content.abstract\n",
    "    dict_['body_text']= content.body_text\n",
    "    dict_['metadata'] = content.metadata\n",
    "    \n",
    "    # add the journal information\n",
    "    if not check_nan(meta_data['journal'].values[0]):\n",
    "        dict_['journal'] = meta_data['journal'].values[0]\n",
    "    else:\n",
    "        dict_['journal'] = None\n",
    "        \n",
    "        \n",
    "    if 'doi' in meta_data:\n",
    "        if not check_nan(meta_data['doi'].values[0]):\n",
    "            dict_['doi'] = meta_data['doi'].values[0]\n",
    "        else:\n",
    "            dict_['doi'] = None\n",
    "    else:\n",
    "        dict_['doi'] = None\n",
    "        \n",
    "    if 'pubmed_id' in meta_data:\n",
    "        if not check_nan(meta_data['pubmed_id'].values[0]):\n",
    "            dict_['pubmed_id'] = meta_data['pubmed_id'].values[0]\n",
    "        else: \n",
    "            dict_['pubmed_id'] = None\n",
    "    else:\n",
    "        dict_['pubmed_id'] = None\n",
    "        \n",
    "    if 'publish_time' in meta_data:\n",
    "        if not check_nan(meta_data['publish_time'].values[0]):\n",
    "            dict_['publish_time'] = meta_data['publish_time'].values[0]\n",
    "        else:\n",
    "            dict_['publish_time'] = None\n",
    "    else:\n",
    "        dict_['publish_time'] = None\n",
    "    \n",
    "        \n",
    "    if 'source_x' in meta_data:\n",
    "        dict_['source_x'] = meta_data['source_x'].values[0]\n",
    "    else:\n",
    "        dict_['source_x'] = None\n",
    "\n",
    "    list_json.append(dict_)\n",
    "#     print(list_json[0])\n",
    "#     print(dict_.keys())\n",
    "#     print(list(meta_data['source_x']))\n",
    "\n",
    "#     break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_id': 'f056da9c64fbf00a4645ae326e8a4339d015d155',\n",
       " 'abstract': 'Next-generation sequencing is increasingly being used to study samples composed of mixtures of organisms, such as in clinical applications where the presence of a pathogen at very low abundance may be highly important. We present an analytical method (SIANN: Strain Identification by Alignment to Near Neighbors) specifically designed to rapidly detect a set of target organisms in mixed samples that achieves a high degree of species-and strain-specificity by aligning short sequence reads to the genomes of near neighbor organisms, as well as that of the target. Empirical benchmarking alongside the current state-of-the-art methods shows an extremely high Positive Predictive Value, even at very low abundances of the target organism in a mixed sample. SIANN is available as an Illumina BaseSpace app, as well as through Signature Science, LLC. SIANN results are presented in a streamlined report designed to be comprehensible to the non-specialist user, providing a powerful tool for rapid species detection in a mixed sample. By focusing on a set of (customizable) target organisms and their near neighbors, SIANN can operate quickly and with low computational requirements while delivering highly accurate results.',\n",
       " 'body_text': 'There are many different methods that characterize the mixture of organisms present within a metagenomic dataset. Such datasets are generated when a complex environmental sample is processed by a \"next-generation\" high-throughput genome sequencing protocol, and they consist of large numbers of short nucleotide sequences. Each sequence represents a small fragment of a randomly selected genome from the very large collection of genomes present in the source sample. Those sequences indicate the presence of one organism or another according to their similarity to a set of known reference genomes. While a given sequence may be unique to one species, it also may be found in diverse organisms across the tree of life. Therefore, one analytical challenge (among many) is to take that collection of sequences (likely numbering in the millions) and accurately determine what species are present in the sample. Here we describe a novel method (SIANN: Strain Identification by Alignment to Near Neighbors) that is specifically designed to rapidly detect a set of targeted organisms from a metagenomic dataset by aligning reads to genomic regions that are unique at the strain or species level.\\nThe analytical question motivating a particular piece of metagenomic bioinformatic analysis may vary widely by user and sample type (Segata, et al., 2013) . For example, the function of the human gut microbiome may depend on the relative abundance of hundreds of species of bacteria and the types of metabolic genes they contain (Wu, et al., 2011; Schloissnig, et al., 2013) . In contrast, the clinical treatment of a patient may depend on whether or not a particular virus, or a consortium of co-infecting pathogens, is/are detected in their blood. It is this second class of presence/absence questions that SIANN is designed to address. SIANN is appropriate for situations in which a user wants to know whether a particular organism or set of organisms is present in a sample, but isn\\'t interested in the functions encoded in their genomes, the relative abundance of each organism, or any other more in-depth analysis.\\nMetagenomic classification methods are based on a wide variety of theoretical underpinnings. The basic varieties include alignment of reads to various nucleotide databases or exact matching to nucleotide or protein signature sequences (or kmers). A representative set of recent methods are described in Table 1 (also see Bazinet & Cummings 2012) .\\nAlignment to large nucleotide database Huson, et al., 2011 PhymmBL Alignment to large nucleotide database with interpolated Markov models Brady & Salzberg, 2011 Metaphyler Alignment to clade-specific marker genes Liu, et al., Overall, these methods are designed to either classify individual reads to, and/or predict the total abundance of, clades (e.g. genus or species) across the entire tree of life. They generally require reference databases that are very large and/or require a large amount of processing to generate. The gap SIANN is designed to fill is when the entire tree of life is irrelevant, and only predefined subsets of organisms need to be detected. For an underlying method we chose read alignment to diagnostic genomic regions because the algorithms for read alignment are highly parallelizable and have been optimized heavily by the community at large (the current implementation of SIANN uses bowtie2 [Langmead & Salzberg, 2012] for the alignment function, but can be adapted to any alignment algorithm). This approach is distinct from using cladespecific marker genes (Segata, et al., 2012) because unique regions that are larger, smaller, or outside of genes can also be used. Furthermore, this approach supports the rapid construction of custom databases using reference genome sets that require only minimal user-supplied structure.\\nTo understand the principle at work, consider a set of reads that have been aligned to the genomes of several strains belonging to two species. Some regions of those genomes are species-specific, some are strain-specific, and some are shared ( Figure  1a ). When a set of reads is aligned to those genomes such that each read is placed in as many locations as it has a match (at a reasonably stringent threshold), visual inspection of the distribution of reads yields an intuitive understanding of the true source organism as Species I/Strain B (Figure 1b ). If Strain B were not present in the reference database, it would still be clear that the organism was an unknown strain of Species I.\\nThe unique identification of a species or strain is quantified by the proportion of the genome that is determined to be species-or strain-specific (defined as reads that are aligned to regions that are species-or strain-specific). Each species and strain is then assigned a numerical measure of the proportion that is covered by these diagnostic reads, and that proportional measure is compared to the ideal case, where sequences from a single organism (generated in silico) are aligned against the database in an identical manner. After that normalization factor is applied, the resulting score indicates whether the source sample contained any of the organisms in the reference database. Figure 1 . A) For a group of strains belonging to two different species, some regions may be unique to each species (region 1), while other regions may be unique to strains within each species (regions 2 and 3). B) A set of reads are aligned to these genomes, and the ones that align in a species-or strain-specific manner are identified by the combination of genomes to which they align. In this example, Strain B of Species I is the organism identified.\\nThe analysis is conducted independently on both the species and the strain level, so that if the true strain is not present in the database, the species of origin will still be identified. While many methods consider the complete taxonomic tree and assign reads to the least common ancestor, SIANN considers only two taxonomic levels: species and strain, throwing out anything that is not unique at one of those levels and thus obviating many of the confounding factors introduced by manually curated taxonomies.\\nThe example shown in Figure 1b indicates that species-specific reads are identified as reads that align to one species (Species I, in that case) but not the other. If Species II were not present in the example shown in Figure 1b , a much larger number of reads would be assigned as \"species-specific,\" when in fact those regions are shared with other species. Therefore, the ability of this method to identify strain-and species-specific sequences is a direct function of the inclusion of near neighbors in the reference database. This characteristic is shared among many classification algorithms, but it is of particular note for this method when users have an opportunity to construct their own database.. In order to detect a target species with a high degree of specificity (reducing false positives), it is necessary to include other related species in the reference database. Only by parallel alignment to those near neighbors can the redundant sequences be separated from the species-specific ones. For example, in order to detect Bacillus anthracis in a sample, it would be necessary to include other species of Bacilli in the reference database so that the presence of B. cereus or B. thuringiensis in a sample does not lead to a false call for B. anthracis.\\nThe nomenclature of genus, species, and strain is potentially problematic because it does not correspond to a consistent degree of evolutionary distance or genomic distinctiveness. The ability to distinguish two organisms by any method using genomic sequence data is proportional to the amount of each genome that is shared or unique. One might assume that any two organisms of the same species will have a relatively predictable amount of shared genomic identity. However, some pairs of organisms from the same species may have less in common than other pairs of organisms from different species or even genera. This ambiguity impacts SIANN in two ways. If two organisms have very little genomic sequence to distinguish them, the sensitivity of SIANN to detect either one will diminish (the rate of false negatives will increase as the likelihood of sequencing unique regions decreases). Conversely, if an organism is extremely dissimilar to the near neighbors selected for the database, the specificity with which SIANN detects that organism will decline (the rate of false positives will increase as the number of related genomes available in the database decreases). For example, if a database contained only E. coli and B.anthracis, a sample containing B. cereus would be misidentified as contraining B. anthracis. In the intended use case, a database targeting B. anthracis would contain B. cereus and a number of other near neighbors to prevent that kind of misidentification. It would be convenient to say that an ideal database can be made by calculating the ideal genetic distance between all references and then finding an ideal set of organisms to make up that database, but the behavior of any database will be governed by the particular genomes of the organisms it encounters in the wild. Because not all organisms evolve in the same manner (differences in mutation rate, horizontal gene transfer, recombination, etc), the suitability of a database and method to detect a given organism can only be determined by thorough validation and benchmarking, as well as updating the reference database as needed. Users of SIANN may construct their own custom databases to include newly identified genomes or specific subsets of genomes that best suit their research interests.\\nSteps to construct a custom database:\\n1. Select a set of target organisms 2. Gather a set of genome sequences for those target organisms as well as a matched set of near neighbors 3. Using those reference genome sequences as an input, SIANN will: a. Construct a reference index for alignment b. Simulate a set of reads from each genome c. Align each of those simulated read sets to all of the reference genomes d. Calculate the proportion of each reference genome that is strain-or species-specific e. [If two organisms do not have a minimal amount of unique sequences that exceeds the rate of sequencing error, SIANN asks that all but one of those organisms are removed from the database to eliminate redundancy. Note that the user can provide a single representative genome with multiple strain names so that the redundant strain names are not lost.]\\nThe files contained within each SIANN database are a compressed genomic index and a list containing the proportion of each reference genome that was found to be strainor species-specific during database construction.\\nTo run SIANN:\\n1. Select a pre-made SIANN database and a set of sequences to be analyzed, and 2. SIANN will: a. Align each of the reads against the reference genomes b. Calculate the proportion of each reference genome that is strain-or species-specific within those reads c. Compare that proportion to the simulated ideal case generated during database creation . CC-BY-NC-ND 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/001727 doi: bioRxiv preprint d. Calculate the probability that the given results could be generated by random chance e. Report the normalized proportion and non-parametric statistic of likelihood for each strain and species in the reference database. The normalized proportion of the genome covered by strain-or speciesspecific reads is the primary statistic reported by this tool.\\nThe performance of SIANN (version 1.6) was tested in comparison to the following stateof-the-art metagenomic classification programs: LMAT (version 1.2), MetaPhlAn (version 1.7.7), and Kraken (version 0.9.1b). All of the programs in Table 1 were investigated for this effort, and three were chosen based on their ability to run on our high-performance computing cluster with an execution time and memory requirement that would be suitable to a clinical lab. Each program was run on a set of 600 simulated datasets generated by MetaSim (Richter, et al., 2008) . Each dataset consisted of 15,000,000 reads (100bp single-ended) with Illumina-simulated error (fourth-degree polynomial) (Korbel, et al., 2009) . The 600 datasets were broken into 12 sets of 50 replicates. Each of the 12 sets contained organisms at different levels of abundance as shown in Table 2 .\\nOrganisms were specifically chosen in pairs so that the ability to distinguish these near neighbors could be determined. The abundances were staggered at 4-fold intervals so that a wide range could be evaluated. All known species of near neighbors for each of the 12 target organisms were included in the reference database used by SIANN for this benchmarking (\"Target Pathogen Database\") and are shown in Appendix 1.\\nEach program outputs a distinct measure. Kraken and LMAT both count the reads assigned to each taxon, MetaPhlAn calculates the abundance, and SIANN outputs a measure of the proportion of diagnostic genomic regions present. To put these measures on an even footing, we empirically calculated the false positive rate for each method over all 600 samples, at each possible measure of output. Because each dataset is made up of known organisms, any result can be classified as true or false. Therefore, for any possible result (say, 513 reads classified by LMAT or 1.6% abundance assigned by MetaPhlAn), one can calculate the proportion of calls with at least the same amount of support that were correct (True Positives/[True Positives+False Positives]), over all of the 600 datasets. That measure is commonly given as Positive Predictive Value (PPV). For each program, the results can be translated from the raw value into a PPV that is based on this empirical measure of error. The key item of interest is the PPV value for the results that we know to be true positives, the defined spike organisms. Another way of describing this approach is to say that the results of each program have been normalized to the false positive error rate that was empirically observed. If another set of samples were generated, the PPV vs. raw value curve ( Figure 2 ) would likely fall differently, but in this case it gives us a means of comparing a diverse set of methods against the same ground truth. If method 1 detects an organism with a higher PPV than method 2 does, it means that method 1 has fewer false positives in the range that it reports true positives, which is the definition of utility in this setting.\\nFor each method, PPV was calculated as a function of raw output value. Briefly, this was done by compiling the output for all 600 samples, labeling each result as false or true based on the sample set that it came from, and then calculating (at each possible value of output) what the proportion of TP/[TP+FP] was for results with at least that level of raw output. Some simplification steps were taken, such as focusing on the specieslevel assignments (for comparison with methods that do not perform strain assignment), and only taking the top hit for each species from each dataset. Custom R and BASH scripts were used for the data compilation and analysis.\\nThe relationship of raw output value to PPV is shown for each of the four methods in Figure 2 . The point at which PPV is very close to 1 (where 95% of results are true positives) is ~41,000 reads for Kraken, ~2,800 reads for LMAT, ~38% abundance for MetaPhlAn, and 0.21 for SIANN. For SIANN this means that having 38% of the species-unique genome covered by reads resulted in the vast majority of calls being accurate. . CC-BY-NC-ND 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/001727 doi: bioRxiv preprint For readassignment methods (such as LMAT and Kraken), manual inspection of the results may yield a different understanding of confidence than is presented here, or in any automated analysis.\\nFor example, while each read that is assigned by LMAT and Kraken fall above a certain cutoff for speciesspecificity, some individual reads may be much more specific than others. One could identify a read that aligns to a single species of bacteria with 100% accuracy over its 300bp length, with the next closest match being only 90% similar. It is extremely unlikely that a 300bp exact match would arise due to random chance, and so the user could say with confidence that the organism of interest is found within the sequence data (not considering contamination, horizontal gene transfer, etc). However, such an approach is not currently implemented in an automated method, and many of the steps needed to make that assertion are performed manually by a domain expert, including alignment to near neighbors and ensuring that the read does not fall within a transposon, plasmid, etc. Therefore, while one could say that a single read is all that is needed to state with high PPV that an organism is present, the amount of reads assigned in an automated manner needed to achieve that level of PPV will number in the thousands (Fig 2) . Table 2 ), and each program (boxes at top), across a maximum of 50 replicates (indicated by the size of each point). Note that the reference database for MetaPhlAn does not include viruses, and the reference database for Kraken does not include RNA viruses (e.g., Hanta virus).\\n. CC-BY-NC-ND 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/001727 doi: bioRxiv preprint The next phase of benchmarking was to determine how many raw input reads were needed to achieve the threshold for high PPV. To demonstrate this we plotted the known abundance of each spike organism against the PPV value generated by each method (Figure 3 ). Each point (an organism at a known level of abundance) is comprised of a maximum of 50 replicates, where the diameter of each point increases with an increasing number of replicates. For demonstration purposes we are showing two pairs of bacteria and three viruses. Recall that for each of the pairs of bacteria (and the two poxviruses) any sample containing one did not contain the other (as shown in Table 1 ). The empty boxes result from the organisms not being called at any abundance. For MetaPhlAn, that is a result of no viruses being included in the version of the reference database available for this analysis. Kraken assigned no reads to Hanta virus because viral RNA genomes were not included in this version of the reference database (personal communication with D. Wood). This emphasizes the point that a) the ability to create custom databases targeting organisms of interest can be valuable, and b) the performance of any method must be benchmarked against each potential target of interest.\\nAll methods were able identify the bulk of organisms in their databases at high abundances (75% and 18%, Figure 3 ), however performance varied considerably at lower abundances and depended on the particular organism and method used. SIANN detected each organism at high confidence, even at levels as low as 0.3% and 0.07% of the total.\\nThe process of detecting trace amounts of a specific organism in a complex mixture of DNA is challenging enough for an expert, but that pales in comparison to the difficulty of accomplishing the same certainty of detection in an automated manner. The results presented here show that SIANN rapidly detects the presence of a given set of organisms with a high degree of specificity and sensitivity. For example, at the 95% confidence (PPV) cutoff of 0.2, SIANN reliably detects all of the organisms tested here at as low as 0.3% abundance. This strong performance is likely due to the fact that SIANN is able to use a method (read alignment to whole genomes) that would be far too computationally costly if it were applied to the entire collection of known genomes. By focusing on a set of (customizable) target organisms and their near neighbors, SIANN can operate quickly and with low computational requirements while delivering highly accurate results. SIANN is available on Illumina\\'s BaseSpace (www.basespace.illumina.com) as a NativeApp, with the database tested here (Appendix 1), as well as a database made from the NCBI representative set of prokaryotic genomes (ftp://ftp.ncbi.nlm.nih.gov/genomes/genome_reports/) (Appendix 2) and the complete set of NCBI viral genomes (ftp://ftp.ncbi.nlm.nih.gov/refseq/release/viral/) (Appendix 3).\\n. CC-BY-NC-ND 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/001727 doi: bioRxiv preprint BaseSpace was chosen as an appropriate release platform because while the entire set of software and dependencies can be deployed by the user from within a graphical user interface, the actual computation takes place in a controlled \\'cloud\\' environment. Such a distribution strategy obviates the need to satisfy the multiple software or OS dependencies that often arises with academic computational methods. Results for SIANN are compiled into a report format, showing both the organisms that surpass 95% confidence, as well as the closest strain match for each species. The default view masks the raw data output, so that the results are human-readable and do not present extraneous information. While the code for execution and databaseconstruction on a users system is available from Signature Science, LLC, additional databases on the BaseSpace platform can be made available upon request.\\nThere is a neverending list of questions that one could ask of metagenomic sequencing data generated from important samples. Instead of answering them all, we demonstrate a technique with a very narrow focus that is able to report with a high degree of confidence whether a given set of organisms is present in a sample. These results are presented to the user in a comprehensible format, and accessible on a commonly-used web platform. The world of bioinformatics will continue to progress and develop more sophisticated tools for metagenomic analysis, and we hope that the utility of SIANN will convince others to package and benchmark their tools in a way that they can be used with confidence by the larger public, as well as the research community.\\n. CC-BY-NC-ND 4.0 International license is made available under a The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. The copyright holder for this preprint (which was not peer-reviewed) is the author/funder. It . https://doi.org/10.1101/001727 doi: bioRxiv preprint',\n",
       " 'metadata': {'title': 'SIANN: Strain Identification by Alignment to Near Neighbors',\n",
       "  'authors': [{'first': 'Samuel',\n",
       "    'middle': ['S'],\n",
       "    'last': 'Minot',\n",
       "    'suffix': '',\n",
       "    'affiliation': {},\n",
       "    'email': ''},\n",
       "   {'first': 'Stephen',\n",
       "    'middle': ['D'],\n",
       "    'last': 'Turner',\n",
       "    'suffix': '',\n",
       "    'affiliation': {},\n",
       "    'email': ''},\n",
       "   {'first': 'Krista',\n",
       "    'middle': ['L'],\n",
       "    'last': 'Ternus',\n",
       "    'suffix': '',\n",
       "    'affiliation': {},\n",
       "    'email': ''},\n",
       "   {'first': 'Dana',\n",
       "    'middle': ['R'],\n",
       "    'last': 'Kadavy',\n",
       "    'suffix': '',\n",
       "    'affiliation': {},\n",
       "    'email': ''}]},\n",
       " 'journal': None,\n",
       " 'doi': '10.1101/001727',\n",
       " 'pubmed_id': None,\n",
       " 'publish_time': None,\n",
       " 'source_x': 'biorxiv'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3345/27678 [01:47<12:15, 33.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3814/27678 [02:01<11:48, 33.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 4144/27678 [02:11<11:22, 34.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 4275/27678 [02:16<11:04, 35.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n",
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4419/27678 [02:20<12:07, 31.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 4511/27678 [02:23<12:03, 32.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4632/27678 [02:27<11:28, 33.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4676/27678 [02:28<11:34, 33.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4708/27678 [02:29<11:27, 33.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 4848/27678 [02:34<12:26, 30.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 4908/27678 [02:36<11:50, 32.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5012/27678 [02:39<10:38, 35.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 5088/27678 [02:42<11:13, 33.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 5149/27678 [02:43<10:31, 35.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5318/27678 [02:49<12:04, 30.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5370/27678 [02:50<11:35, 32.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 5378/27678 [02:51<11:02, 33.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 5402/27678 [02:51<11:38, 31.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 5503/27678 [02:54<11:01, 33.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5698/27678 [03:01<10:48, 33.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5759/27678 [03:02<10:35, 34.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6268/27678 [03:19<10:10, 35.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6622/27678 [03:30<10:59, 31.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n",
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 6801/27678 [03:37<11:09, 31.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 6805/27678 [03:37<11:14, 30.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 6962/27678 [03:43<12:18, 28.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 7313/27678 [03:55<10:36, 32.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 7353/27678 [03:57<11:22, 29.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 7521/27678 [04:03<11:07, 30.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 7531/27678 [04:03<13:24, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 7564/27678 [04:04<11:07, 30.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7678/27678 [04:09<16:02, 20.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 7907/27678 [04:16<09:58, 33.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 7941/27678 [04:18<10:43, 30.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7960/27678 [04:18<10:55, 30.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 8020/27678 [04:20<09:50, 33.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 8032/27678 [04:21<10:18, 31.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 8203/27678 [04:27<10:52, 29.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 8211/27678 [04:27<10:14, 31.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 8251/27678 [04:28<10:33, 30.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 8383/27678 [04:33<10:28, 30.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 8406/27678 [04:33<10:17, 31.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 8506/27678 [04:37<10:35, 30.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 8576/27678 [04:39<10:40, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8796/27678 [04:47<10:24, 30.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8950/27678 [04:52<09:49, 31.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8996/27678 [04:54<10:11, 30.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n",
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 26685/27678 [14:49<00:28, 34.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 27184/27678 [15:06<00:15, 32.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 27256/27678 [15:09<00:12, 33.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 27432/27678 [15:15<00:09, 26.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 27463/27678 [15:16<00:06, 32.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publish_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27678/27678 [15:23<00:00, 29.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "\n",
    "# es = Elasticsearch({'host':'csxindex05', 'port':9200})\n",
    "es = Elasticsearch(['http://csxindex05:9200/'], verify_certs=True)\n",
    "\n",
    "for jsons in tqdm(list_json):\n",
    "    try:\n",
    "        es.index(index = \"cord_meta\", body = jsons)\n",
    "    except:\n",
    "        for i in jsons:\n",
    "            if check_nan(jsons[i]):\n",
    "                print(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import uuid\n",
    "es = Elasticsearch(['http://csxindex05:9200/'], verify_certs=True)\n",
    "\n",
    "if not es.ping():\n",
    "    raise ValueError(\"Connection failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'cord_journal'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"publish_time\": {\n",
    "                \"type\": \"text\" # formerly \"string\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.create(\n",
    "    index=\"cord_journal\",\n",
    "    body=mapping,\n",
    "    ignore=400 # ignore 400 already exists code\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_a = []\n",
    "\n",
    "for obj in tqdm(list_json):\n",
    "    dict_item = {  \"_index\": \"cord_journal\",\n",
    "                            \"_id\": uuid.uuid4(),\n",
    "                            \"_source\": obj }\n",
    "    list_a.append(dict_item)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27678, [])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpers.bulk(es, list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27678"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
